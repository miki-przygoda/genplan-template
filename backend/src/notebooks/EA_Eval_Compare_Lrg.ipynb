{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edf1089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "try:\n",
    "    from scipy import stats\n",
    "    SCIPY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SCIPY_AVAILABLE = False\n",
    "\n",
    "\n",
    "FIG_DIR = None\n",
    "TABLE_DIR = None\n",
    "\n",
    "\n",
    "def find_eval_dir():\n",
    "    cwd = Path.cwd()\n",
    "    candidates = []\n",
    "    for base in [cwd, *cwd.parents]:\n",
    "        candidates.append(base / \"backend/data/ea-logs/json\")\n",
    "        candidates.append(base / \"data/ea-logs/json\")\n",
    "    for cand in candidates:\n",
    "        if cand.is_dir():\n",
    "            return cand\n",
    "    raise FileNotFoundError(\"Could not locate backend/data/ea-logs/json\")\n",
    "\n",
    "\n",
    "def mean_curve(histories):\n",
    "    histories = [h for h in histories if isinstance(h, (list, tuple)) and len(h) > 0]\n",
    "    if not histories:\n",
    "        return []\n",
    "    max_len = max(len(h) for h in histories)\n",
    "    mat = np.full((len(histories), max_len), np.nan)\n",
    "    for i, h in enumerate(histories):\n",
    "        mat[i, : len(h)] = h\n",
    "    return np.nanmean(mat, axis=0)\n",
    "\n",
    "\n",
    "def cliffs_delta(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    total = len(x) * len(y)\n",
    "    if total == 0:\n",
    "        return np.nan\n",
    "    gt = 0\n",
    "    lt = 0\n",
    "    for xi in x:\n",
    "        gt += np.sum(xi > y)\n",
    "        lt += np.sum(xi < y)\n",
    "    return (gt - lt) / total\n",
    "\n",
    "\n",
    "def safe_slug(text):\n",
    "    slug = \"\".join(ch if ch.isalnum() or ch in (\"-\", \"_\") else \"_\" for ch in str(text))\n",
    "    slug = slug.strip(\"_\")\n",
    "    return slug or \"figure\"\n",
    "\n",
    "\n",
    "def setup_output_dirs(eval_dir):\n",
    "    data_dir = eval_dir.parent.parent\n",
    "    fig_dir = data_dir / \"figures\"\n",
    "    table_dir = fig_dir / \"tables\"\n",
    "    fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "    table_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return fig_dir, table_dir\n",
    "\n",
    "\n",
    "def save_figure(fig, name, subdir=None):\n",
    "    target_dir = FIG_DIR if subdir is None else FIG_DIR / safe_slug(subdir)\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    path = target_dir / f\"{safe_slug(name)}.pdf\"\n",
    "    fig.savefig(path, bbox_inches=\"tight\")\n",
    "    print(\"Saved figure:\", path)\n",
    "    return path\n",
    "\n",
    "\n",
    "def save_table(df, name, subdir=None, index=True, float_fmt=\"%.4f\"):\n",
    "    target_dir = TABLE_DIR if subdir is None else TABLE_DIR / safe_slug(subdir)\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    slug = safe_slug(name)\n",
    "    csv_path = target_dir / f\"{slug}.csv\"\n",
    "    tex_path = target_dir / f\"{slug}.tex\"\n",
    "    df.to_csv(csv_path, index=index)\n",
    "    latex_written = False\n",
    "    try:\n",
    "        tex_content = df.to_latex(index=index, float_format=float_fmt)\n",
    "        tex_path.write_text(tex_content)\n",
    "        latex_written = True\n",
    "    except ImportError:\n",
    "        tex_path = None\n",
    "        print(\"Jinja2 not installed; skipping LaTeX export for\", name)\n",
    "    if latex_written:\n",
    "        print(\"Saved table (csv & tex):\", csv_path, tex_path)\n",
    "    else:\n",
    "        print(\"Saved table (csv only):\", csv_path)\n",
    "    return csv_path, tex_path\n",
    "\n",
    "\n",
    "EVAL_DIR = find_eval_dir()\n",
    "FIG_DIR, TABLE_DIR = setup_output_dirs(EVAL_DIR)\n",
    "print(\"Using EVAL_DIR:\", EVAL_DIR)\n",
    "print(\"Saving figures to:\", FIG_DIR)\n",
    "print(\"Saving tables to:\", TABLE_DIR)\n",
    "\n",
    "rows = []\n",
    "for path in sorted(EVAL_DIR.glob(\"ea_run_*.json\")):\n",
    "    with path.open() as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    runs_by_variant = {r[\"variant\"]: r for r in data.get(\"runs\", [])}\n",
    "    if not {\"ea_rl\", \"ea_only\"} <= runs_by_variant.keys():\n",
    "        print(f\"Skipping {path.name}: missing expected variants\")\n",
    "        continue\n",
    "\n",
    "    cfg = data[\"config\"]\n",
    "    rl_run = runs_by_variant[\"ea_rl\"]\n",
    "    ea_run = runs_by_variant[\"ea_only\"]\n",
    "\n",
    "    rl_constraints = rl_run.get(\"best_constraints\", {}) or {}\n",
    "    ea_constraints = ea_run.get(\"best_constraints\", {}) or {}\n",
    "\n",
    "    rows.append({\n",
    "        \"file\": path.name,\n",
    "        \"run_id\": data.get(\"run_id\"),\n",
    "        \"floor_id\": data.get(\"floor_id\"),\n",
    "        \"grid_size\": data.get(\"grid_size\"),\n",
    "        \"rotate_k\": data.get(\"rotate_k\"),\n",
    "        \"gens\": cfg.get(\"generations\"),\n",
    "        \"population\": cfg.get(\"population_size\"),\n",
    "\n",
    "        \"rl_best\": rl_run.get(\"best_fitness_final\"),\n",
    "        \"rl_best_initial\": rl_run.get(\"best_fitness_initial\"),\n",
    "        \"rl_gen_at_best\": rl_run.get(\"gen_at_best\"),\n",
    "        \"rl_duration_s\": rl_run.get(\"duration_s\"),\n",
    "        \"rl_is_real\": rl_run.get(\"is_real\"),\n",
    "        \"rl_realism_score\": rl_run.get(\"realism_score\"),\n",
    "        \"rl_history\": rl_run.get(\"history\", []),\n",
    "        \"rl_bandit_arm\": rl_run.get(\"bandit_arm_index\"),\n",
    "        \"rl_bandit_reward\": rl_run.get(\"bandit_reward\"),\n",
    "        \"rl_seeder\": rl_run.get(\"seeder_name\"),\n",
    "        \"rl_mask\": rl_constraints.get(\"mask\"),\n",
    "        \"rl_compactness\": rl_constraints.get(\"compactness\"),\n",
    "        \"rl_holes\": rl_constraints.get(\"holes\"),\n",
    "        \"rl_area\": rl_constraints.get(\"area\"),\n",
    "        \"rl_budget\": rl_constraints.get(\"budget\"),\n",
    "\n",
    "        \"ea_best\": ea_run.get(\"best_fitness_final\"),\n",
    "        \"ea_best_initial\": ea_run.get(\"best_fitness_initial\"),\n",
    "        \"ea_gen_at_best\": ea_run.get(\"gen_at_best\"),\n",
    "        \"ea_duration_s\": ea_run.get(\"duration_s\"),\n",
    "        \"ea_is_real\": ea_run.get(\"is_real\"),\n",
    "        \"ea_realism_score\": ea_run.get(\"realism_score\"),\n",
    "        \"ea_history\": ea_run.get(\"history\", []),\n",
    "        \"ea_bandit_arm\": ea_run.get(\"bandit_arm_index\"),\n",
    "        \"ea_bandit_reward\": ea_run.get(\"bandit_reward\"),\n",
    "        \"ea_seeder\": ea_run.get(\"seeder_name\"),\n",
    "        \"ea_mask\": ea_constraints.get(\"mask\"),\n",
    "        \"ea_compactness\": ea_constraints.get(\"compactness\"),\n",
    "        \"ea_holes\": ea_constraints.get(\"holes\"),\n",
    "        \"ea_area\": ea_constraints.get(\"area\"),\n",
    "        \"ea_budget\": ea_constraints.get(\"budget\"),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "if df.empty:\n",
    "    print(f\"No runs found in {EVAL_DIR}\")\n",
    "else:\n",
    "    display(df.head())\n",
    "\n",
    "    df[\"improvement_abs\"] = df[\"ea_best\"] - df[\"rl_best\"]\n",
    "    df[\"improvement_rel\"] = (df[\"ea_best\"] - df[\"rl_best\"]) / df[\"ea_best\"]\n",
    "    df[\"ea_relative_improvement\"] = (df[\"ea_best\"] - df[\"rl_best\"]) / df[\"rl_best\"]\n",
    "    df[\"rl_better\"] = df[\"rl_best\"] < df[\"ea_best\"]\n",
    "    df[\"time_speedup_s\"] = df[\"ea_duration_s\"] - df[\"rl_duration_s\"]\n",
    "\n",
    "    df[\"rl_efficiency\"] = df[\"rl_best\"] / df[\"rl_duration_s\"]\n",
    "    df[\"ea_efficiency\"] = df[\"ea_best\"] / df[\"ea_duration_s\"]\n",
    "    duration_delta = df[\"rl_duration_s\"] - df[\"ea_duration_s\"]\n",
    "    df[\"improvement_cost\"] = (df[\"ea_best\"] - df[\"rl_best\"]) / duration_delta\n",
    "    df.loc[duration_delta == 0, \"improvement_cost\"] = pd.NA\n",
    "\n",
    "    df[\"rl_convergence_rate\"] = (\n",
    "        (df[\"rl_best_initial\"] - df[\"rl_best\"]) / df[\"rl_gen_at_best\"]\n",
    "    )\n",
    "    df[\"ea_convergence_rate\"] = (\n",
    "        (df[\"ea_best_initial\"] - df[\"ea_best\"]) / df[\"ea_gen_at_best\"]\n",
    "    )\n",
    "    df.loc[df[\"rl_gen_at_best\"] == 0, \"rl_convergence_rate\"] = pd.NA\n",
    "    df.loc[df[\"ea_gen_at_best\"] == 0, \"ea_convergence_rate\"] = pd.NA\n",
    "\n",
    "    metrics_export = df.drop(columns=[\"rl_history\", \"ea_history\"], errors=\"ignore\")\n",
    "    save_table(metrics_export, \"all_runs_metrics\")\n",
    "\n",
    "    n_runs = len(df)\n",
    "    print(\"Total paired runs:\", n_runs)\n",
    "    print(\"RL better in:\", df[\"rl_better\"].sum(), \"runs\")\n",
    "    print(\"RL better (%):\", 100 * df[\"rl_better\"].mean())\n",
    "\n",
    "    print(\"Mean best fitness:\")\n",
    "    print(\"  RL:\", df[\"rl_best\"].mean())\n",
    "    print(\"  EA:\", df[\"ea_best\"].mean())\n",
    "\n",
    "    print(\"Median best fitness:\")\n",
    "    print(\"  RL:\", df[\"rl_best\"].median())\n",
    "    print(\"  EA:\", df[\"ea_best\"].median())\n",
    "\n",
    "    print(\"Mean relative improvement (%):\", 100 * df[\"improvement_rel\"].mean())\n",
    "    print(\"Median relative improvement (%):\", 100 * df[\"improvement_rel\"].median())\n",
    "    print(\"Mean relative improvement for EA-only (RL denom) (%):\", 100 * df[\"ea_relative_improvement\"].mean())\n",
    "    print(\"Median relative improvement for EA-only (RL denom) (%):\", 100 * df[\"ea_relative_improvement\"].median())\n",
    "\n",
    "    print(\"Mean gen_at_best:\")\n",
    "    print(\"  RL:\", df[\"rl_gen_at_best\"].mean())\n",
    "    print(\"  EA:\", df[\"ea_gen_at_best\"].mean())\n",
    "\n",
    "    print(\"Mean duration (s):\")\n",
    "    print(\"  RL:\", df[\"rl_duration_s\"].mean())\n",
    "    print(\"  EA:\", df[\"ea_duration_s\"].mean())\n",
    "\n",
    "    # Hist / box / scatter\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    plt.hist(df[\"improvement_abs\"], bins=40)\n",
    "    plt.axvline(0, linestyle=\"--\")\n",
    "    plt.xlabel(\"ea_best - rl_best (positive = RL better)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\"Distribution of RL advantage over pure EA\")\n",
    "    save_figure(fig, \"rl_advantage_distribution\")\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    plt.boxplot([df[\"rl_best\"], df[\"ea_best\"]], tick_labels=[\"EA+RL\", \"EA only\"])\n",
    "    plt.ylabel(\"Best fitness (lower is better)\")\n",
    "    plt.title(\"Best fitness across paired runs\")\n",
    "    save_figure(fig, \"best_fitness_boxplot\")\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(df[\"ea_best\"], df[\"rl_best\"], alpha=0.5)\n",
    "    ea_min, ea_max = df[\"ea_best\"].min(), df[\"ea_best\"].max()\n",
    "    plt.plot([ea_min, ea_max], [ea_min, ea_max], linestyle=\"--\")\n",
    "    plt.xlabel(\"EA only best fitness\")\n",
    "    plt.ylabel(\"EA+RL best fitness\")\n",
    "    plt.title(\"Per-run comparison of best fitness\")\n",
    "    save_figure(fig, \"per_run_best_fitness_scatter\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Per-floor performance summary:\")\n",
    "    floor_summary = (\n",
    "        df.groupby(\"floor_id\")\n",
    "        .agg(\n",
    "            rl_best_mean=(\"rl_best\", \"mean\"),\n",
    "            ea_best_mean=(\"ea_best\", \"mean\"),\n",
    "            rl_win_rate=(\"rl_better\", \"mean\"),\n",
    "            avg_improvement=(\"improvement_abs\", \"mean\"),\n",
    "            avg_time_delta_s=(\"time_speedup_s\", \"mean\"),\n",
    "            runs=(\"file\", \"count\"),\n",
    "        )\n",
    "        .sort_index()\n",
    "    )\n",
    "    display(floor_summary)\n",
    "    save_table(floor_summary.reset_index(), \"floor_performance_summary\")\n",
    "\n",
    "    for floor_id, sub in df.groupby(\"floor_id\"):\n",
    "        rl_curve = mean_curve(sub[\"rl_history\"].tolist())\n",
    "        ea_curve = mean_curve(sub[\"ea_history\"].tolist())\n",
    "        if len(rl_curve) == 0 and len(ea_curve) == 0:\n",
    "            continue\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        if len(rl_curve):\n",
    "            ax.plot(rl_curve, label=\"EA+RL mean best\")\n",
    "        if len(ea_curve):\n",
    "            ax.plot(ea_curve, label=\"EA only mean best\")\n",
    "        ax.set_xlabel(\"Generation\")\n",
    "        ax.set_ylabel(\"Best fitness\")\n",
    "        ax.set_title(f\"Mean convergence curve â€” floor {floor_id}\")\n",
    "        ax.legend()\n",
    "        save_figure(fig, f\"floor_{safe_slug(floor_id)}_mean_convergence\", subdir=\"convergence_curves\")\n",
    "        plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(df[\"time_speedup_s\"], df[\"improvement_abs\"], alpha=0.5)\n",
    "    plt.axvline(0, linestyle=\"--\", color=\"gray\")\n",
    "    plt.axhline(0, linestyle=\"--\", color=\"gray\")\n",
    "    plt.xlabel(\"EA duration - RL duration (s)\")\n",
    "    plt.ylabel(\"EA best - RL best (fitness)\")\n",
    "    plt.title(\"Tradeoff: time saved vs fitness gain (positive y = RL better)\")\n",
    "    save_figure(fig, \"time_vs_improvement_tradeoff\")\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    plt.hist(df[\"improvement_cost\"].dropna(), bins=40)\n",
    "    plt.xlabel(\"(EA best - RL best) / (RL time - EA time)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\"Cost per unit improvement (lower is better for RL)\")\n",
    "    save_figure(fig, \"improvement_cost_distribution\")\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    plt.boxplot(\n",
    "        [df[\"rl_convergence_rate\"].dropna(), df[\"ea_convergence_rate\"].dropna()],\n",
    "        tick_labels=[\"EA+RL\", \"EA only\"],\n",
    "    )\n",
    "    plt.ylabel(\"(initial - best) / gen_at_best\")\n",
    "    plt.title(\"Convergence rate comparison\")\n",
    "    save_figure(fig, \"convergence_rate_comparison\")\n",
    "    plt.show()\n",
    "\n",
    "    rl_losses = df[~df[\"rl_better\"]]\n",
    "    if not rl_losses.empty:\n",
    "        print(\"RL losses (EA only better):\", len(rl_losses))\n",
    "        print(\"Top floors where RL lost:\")\n",
    "        print(rl_losses[\"floor_id\"].value_counts().head())\n",
    "        if \"rl_mask\" in rl_losses:\n",
    "            print(\"Mean mask penalty when RL lost:\", rl_losses[\"rl_mask\"].mean())\n",
    "        big_ea_luck = rl_losses.sort_values(\"improvement_abs\").head(5)[\n",
    "            [\"file\", \"floor_id\", \"improvement_abs\", \"ea_best\", \"rl_best\"]\n",
    "        ]\n",
    "        print(\"Example EA-favored runs:\")\n",
    "        print(big_ea_luck)\n",
    "        rl_loss_cols = [\n",
    "            \"file\",\n",
    "            \"floor_id\",\n",
    "            \"improvement_abs\",\n",
    "            \"ea_best\",\n",
    "            \"rl_best\",\n",
    "            \"ea_duration_s\",\n",
    "            \"rl_duration_s\",\n",
    "            \"rl_mask\",\n",
    "            \"ea_mask\",\n",
    "        ]\n",
    "        save_table(rl_losses[rl_loss_cols], \"rl_losses_by_run\", subdir=\"rl_losses\")\n",
    "        save_table(big_ea_luck, \"example_ea_favored_runs\", subdir=\"rl_losses\")\n",
    "\n",
    "    rl_big_wins = df[df[\"improvement_abs\"] > df[\"improvement_abs\"].quantile(0.9)]\n",
    "    if not rl_big_wins.empty:\n",
    "        print(\"RL big wins (top 10% improvement):\", len(rl_big_wins))\n",
    "        print(\"Floors with big wins:\")\n",
    "        print(rl_big_wins[\"floor_id\"].value_counts().head())\n",
    "        if \"rl_mask\" in rl_big_wins:\n",
    "            print(\"Mean mask penalty when RL big win:\", rl_big_wins[\"rl_mask\"].mean())\n",
    "        win_cols = [\n",
    "            \"file\",\n",
    "            \"floor_id\",\n",
    "            \"improvement_abs\",\n",
    "            \"ea_best\",\n",
    "            \"rl_best\",\n",
    "            \"ea_duration_s\",\n",
    "            \"rl_duration_s\",\n",
    "            \"rl_mask\",\n",
    "            \"ea_mask\",\n",
    "        ]\n",
    "        save_table(rl_big_wins[win_cols], \"rl_big_wins\", subdir=\"rl_wins\")\n",
    "\n",
    "    rl_runs = df[df[\"rl_bandit_arm\"].notna()]\n",
    "    if not rl_runs.empty:\n",
    "        arm_summary = (\n",
    "            rl_runs.groupby(\"rl_bandit_arm\")\n",
    "            .agg(\n",
    "                runs=(\"file\", \"count\"),\n",
    "                win_rate=(\"rl_better\", \"mean\"),\n",
    "                mean_reward=(\"rl_bandit_reward\", \"mean\"),\n",
    "                mean_improvement=(\"improvement_abs\", \"mean\"),\n",
    "            )\n",
    "            .sort_index()\n",
    "        )\n",
    "        print(\"Bandit arm performance (EA+RL runs):\")\n",
    "        display(arm_summary)\n",
    "        save_table(arm_summary, \"bandit_arm_performance\")\n",
    "\n",
    "        floor_arm = (\n",
    "            rl_runs.groupby([\"floor_id\", \"rl_bandit_arm\"])\n",
    "            .agg(win_rate=(\"rl_better\", \"mean\"), runs=(\"file\", \"count\"))\n",
    "            .reset_index()\n",
    "        )\n",
    "        print(\"Arm success probability by floor (rows with at least 3 runs):\")\n",
    "        floor_arm_filtered = floor_arm[floor_arm[\"runs\"] >= 3]\n",
    "        floor_arm_pivot = floor_arm_filtered.pivot(\n",
    "            index=\"floor_id\", columns=\"rl_bandit_arm\", values=\"win_rate\"\n",
    "        )\n",
    "        display(floor_arm_pivot)\n",
    "        if not floor_arm_filtered.empty:\n",
    "            save_table(\n",
    "                floor_arm_pivot,\n",
    "                \"arm_success_probability_by_floor\",\n",
    "                subdir=\"bandit_arms\",\n",
    "            )\n",
    "\n",
    "    diffs = (df[\"ea_best\"] - df[\"rl_best\"]).dropna()\n",
    "    if SCIPY_AVAILABLE and len(diffs) > 0:\n",
    "        t_stat, t_p = stats.ttest_rel(df[\"ea_best\"], df[\"rl_best\"])\n",
    "        try:\n",
    "            w_stat, w_p = stats.wilcoxon(df[\"ea_best\"], df[\"rl_best\"])\n",
    "        except ValueError:\n",
    "            w_stat, w_p = (np.nan, np.nan)\n",
    "        d_cohen = diffs.mean() / diffs.std(ddof=1)\n",
    "        delta = cliffs_delta(df[\"ea_best\"], df[\"rl_best\"])\n",
    "        print(\"Significance tests (EA best - RL best):\")\n",
    "        print(f\"  Paired t-test: stat={t_stat:.4f}, p={t_p:.4e}\")\n",
    "        print(f\"  Wilcoxon signed-rank: stat={w_stat}, p={w_p}\")\n",
    "        print(f\"  Cohen's d: {d_cohen:.4f}\")\n",
    "        print(f\"  Cliff's delta: {delta:.4f}\")\n",
    "        sig_rows = [\n",
    "            {\"metric\": \"paired_t_stat\", \"value\": t_stat},\n",
    "            {\"metric\": \"paired_t_p\", \"value\": t_p},\n",
    "            {\"metric\": \"wilcoxon_stat\", \"value\": w_stat},\n",
    "            {\"metric\": \"wilcoxon_p\", \"value\": w_p},\n",
    "            {\"metric\": \"cohens_d\", \"value\": d_cohen},\n",
    "            {\"metric\": \"cliffs_delta\", \"value\": delta},\n",
    "        ]\n",
    "        sig_df = pd.DataFrame(sig_rows)\n",
    "        save_table(sig_df, \"significance_tests\")\n",
    "    else:\n",
    "        print(\"SciPy not available; skipping statistical tests.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genplan-template",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
